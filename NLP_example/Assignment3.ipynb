{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP 551 Assignment 3\n",
    "# Name: Charles Lagace\n",
    "# Student ID: 260698807\n",
    "# This notebook was written with Python 3.6\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import scipy.sparse as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '5', '5', '3', '2', '2', '3', '1', '3', '5', '5', '5', '4', '4', '1', '2', '2', '3', '5', '2']\n",
      "[(45289, 'the', 30739), (30384, 'and', 939), (24943, 'a', 1), (24105, 'i', 14907), (21039, 'to', 31321), (14411, 'of', 20804), (13707, 'was', 33417), (12071, 'is', 15741), (11542, 'it', 15798), (10615, 'for', 11637), (10183, 'in', 15121), (8244, 'that', 30691), (7557, 'my', 19840), (7537, 'with', 34133), (7279, 'but', 4150), (7155, 'you', 34635), (7010, 'this', 30977), (6398, 'they', 30899), (6343, 'on', 21029), (5982, 'have', 13826), (5763, 'we', 33564), (5237, 'not', 20524), (5011, 'had', 13506), (5010, 'are', 1327), (4573, 'place', 22933), (4533, 'good', 12820), (4484, 'so', 28148), (4482, 'at', 1632), (4194, 'were', 33769), (4144, 'food', 11533), (3900, 'be', 2456), (3877, 'as', 1500), (3546, 'there', 30839), (3508, 'great', 13123), (3425, 'like', 17294), (3179, 'if', 14967), (3170, 'its', 15906), (3144, 'me', 18512), (3134, 'all', 636), (3114, 'just', 16326), (3068, 'very', 32994), (3043, 'out', 21414), (2912, 'here', 14069), (2744, 'one', 21046), (2718, 'or', 21250), (2671, 'get', 12507), (2655, 'their', 30759), (2562, 'from', 12053), (2420, 'up', 32576), (2373, 'go', 12733)]\n",
      "10000\n",
      "(7000, 10000) (1000, 10000) (2000, 10000)\n",
      "75 0.0116102428571\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 36)\t1\n",
      "  :\t:\n",
      "  (6999, 201)\t1\n",
      "  (6999, 212)\t1\n",
      "  (6999, 217)\t1\n",
      "  (6999, 224)\t1\n",
      "  (6999, 239)\t1\n",
      "  (6999, 244)\t1\n",
      "  (6999, 274)\t1\n",
      "  (6999, 303)\t1\n",
      "  (6999, 451)\t1\n",
      "  (6999, 479)\t1\n",
      "  (6999, 530)\t1\n",
      "  (6999, 551)\t1\n",
      "  (6999, 642)\t1\n",
      "  (6999, 698)\t1\n",
      "  (6999, 776)\t1\n",
      "  (6999, 868)\t1\n",
      "  (6999, 986)\t1\n",
      "  (6999, 1292)\t1\n",
      "  (6999, 1965)\t1\n",
      "  (6999, 2075)\t1\n",
      "  (6999, 2276)\t1\n",
      "  (6999, 2712)\t1\n",
      "  (6999, 3334)\t1\n",
      "  (6999, 3582)\t1\n",
      "  (6999, 3931)\t1\n",
      "1 0.00775754285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda2/envs/py36/lib/python3.6/site-packages/scipy/sparse/base.py:470: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return self.astype(np.float_)._mul_scalar(1./other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.0591715976331\n",
      "  (0, 1)\t0.0236686390533\n",
      "  (0, 4)\t0.0295857988166\n",
      "  (0, 5)\t0.00591715976331\n",
      "  (0, 6)\t0.00591715976331\n",
      "  (0, 7)\t0.0118343195266\n",
      "  (0, 8)\t0.0118343195266\n",
      "  (0, 10)\t0.0118343195266\n",
      "  (0, 11)\t0.0236686390533\n",
      "  (0, 12)\t0.0177514792899\n",
      "  (0, 13)\t0.00591715976331\n",
      "  (0, 14)\t0.0118343195266\n",
      "  (0, 15)\t0.0118343195266\n",
      "  (0, 16)\t0.00591715976331\n",
      "  (0, 17)\t0.0177514792899\n",
      "  (0, 20)\t0.00591715976331\n",
      "  (0, 22)\t0.00591715976331\n",
      "  (0, 24)\t0.0177514792899\n",
      "  (0, 26)\t0.00591715976331\n",
      "  (0, 27)\t0.00591715976331\n",
      "  (0, 30)\t0.00591715976331\n",
      "  (0, 31)\t0.00591715976331\n",
      "  (0, 32)\t0.00591715976331\n",
      "  (0, 33)\t0.00591715976331\n",
      "  (0, 36)\t0.00591715976331\n",
      "  :\t:\n",
      "  (6999, 201)\t0.0151515151515\n",
      "  (6999, 212)\t0.0151515151515\n",
      "  (6999, 217)\t0.0151515151515\n",
      "  (6999, 224)\t0.0151515151515\n",
      "  (6999, 239)\t0.0151515151515\n",
      "  (6999, 244)\t0.0151515151515\n",
      "  (6999, 274)\t0.0151515151515\n",
      "  (6999, 303)\t0.0151515151515\n",
      "  (6999, 451)\t0.0151515151515\n",
      "  (6999, 479)\t0.0151515151515\n",
      "  (6999, 530)\t0.030303030303\n",
      "  (6999, 551)\t0.0151515151515\n",
      "  (6999, 642)\t0.0151515151515\n",
      "  (6999, 698)\t0.0151515151515\n",
      "  (6999, 776)\t0.0151515151515\n",
      "  (6999, 868)\t0.0151515151515\n",
      "  (6999, 986)\t0.0151515151515\n",
      "  (6999, 1292)\t0.0151515151515\n",
      "  (6999, 1965)\t0.0151515151515\n",
      "  (6999, 2075)\t0.0151515151515\n",
      "  (6999, 2276)\t0.0151515151515\n",
      "  (6999, 2712)\t0.0151515151515\n",
      "  (6999, 3334)\t0.0151515151515\n",
      "  (6999, 3582)\t0.0151515151515\n",
      "  (6999, 3931)\t0.0151515151515\n",
      "1.0 9.99714285714e-05\n"
     ]
    }
   ],
   "source": [
    "# Question 1: preprocess and convert the YELP dataset\n",
    "\n",
    "# train set\n",
    "with open(\"hwk3_datasets/yelp-train.txt\", \"r\") as myfile:\n",
    "    yelp_train = myfile.readlines()\n",
    "    \n",
    "# validation set    \n",
    "with open(\"hwk3_datasets/yelp-valid.txt\", \"r\") as myfile:\n",
    "    yelp_valid = myfile.readlines()\n",
    "    \n",
    "# test set\n",
    "with open(\"hwk3_datasets/yelp-test.txt\", \"r\") as myfile:\n",
    "    yelp_test = myfile.readlines()\n",
    "    \n",
    "yelp_ytrain = [line.split(\"\\t\")[-1][0] for line in yelp_train]\n",
    "yelp_yvalid = [line.split(\"\\t\")[-1][0] for line in yelp_valid]\n",
    "yelp_ytest = [line.split(\"\\t\")[-1][0] for line in yelp_test]\n",
    "\n",
    "# preprocess the data\n",
    "yelp_xtrain_str = [re.sub(r'[^a-zA-Z ]', \"\", line).lower() for line in yelp_train]\n",
    "yelp_xvalid_str = [re.sub(r'[^a-zA-Z ]', \"\", line).lower() for line in yelp_valid]\n",
    "yelp_xtest_str = [re.sub(r'[^a-zA-Z ]', \"\", line).lower() for line in yelp_test]\n",
    "\n",
    "# get unique words\n",
    "words = [text.split(\" \") for text in yelp_xtrain_str]\n",
    "unique_words = set([word for text in words for word in text])\n",
    "vocabulary = dict([(word, i) for i, word in enumerate(sorted(unique_words))])\n",
    "\n",
    "#count word occurrences\n",
    "word_counts = np.zeros(len(unique_words), dtype=np.int32)\n",
    "for text in words:     \n",
    "    # vocabulary[0] = '' (blank character) so we exclude it\n",
    "    index_map = [vocabulary[word] for word in text if vocabulary[word]]\n",
    "    word_counts += np.bincount(np.array(index_map), minlength=len(unique_words))\n",
    "    \n",
    "# get 10000 most frequent words\n",
    "frequent_words = sorted(zip(word_counts, sorted(unique_words), range(len(unique_words))))\n",
    "frequent_words.reverse()\n",
    "frequent_words = frequent_words[:10000]\n",
    "vocabulary = dict([(word[1], i) for i, word in enumerate(frequent_words)])\n",
    "\n",
    "#save the vocabulary\n",
    "with open(\"my_datasets/yelp-vocab.txt\", \"w\") as myfile:\n",
    "    for word in frequent_words:\n",
    "        myfile.write(\"{} {} {}\\n\".format(word[1], vocabulary[word[1]], word[0]))\n",
    "\n",
    "# convert input to int representation\n",
    "yelp_xtrain = [[vocabulary[word] for word in text if word in vocabulary] for text in words]\n",
    "\n",
    "valid_words = [text.split(\" \") for text in yelp_xvalid_str]\n",
    "yelp_xvalid = [[vocabulary[word] for word in text if word in vocabulary] for text in valid_words]\n",
    "\n",
    "test_words = [text.split(\" \") for text in yelp_xtest_str]\n",
    "yelp_xtest = [[vocabulary[word] for word in text if word in vocabulary] for text in test_words]\n",
    "\n",
    "# save training set\n",
    "with open(\"my_datasets/yelp-train.txt\", \"w\") as myfile:\n",
    "    for i, text in enumerate(yelp_xtrain):\n",
    "        text = [str(i) for i in text]\n",
    "        myfile.write(\"{}\\t{}\\n\".format(\" \".join(text), yelp_ytrain[i]))\n",
    "\n",
    "# save validation set\n",
    "with open(\"my_datasets/yelp-valid.txt\", \"w\") as myfile:\n",
    "    for i, text in enumerate(yelp_xvalid):\n",
    "        text = [str(i) for i in text]\n",
    "        myfile.write(\"{}\\t{}\\n\".format(\" \".join(text), yelp_yvalid[i]))\n",
    "\n",
    "# save test set\n",
    "with open(\"my_datasets/yelp-test.txt\", \"w\") as myfile:\n",
    "    for i, text in enumerate(yelp_xtest):\n",
    "        text = [str(i) for i in text]\n",
    "        myfile.write(\"{}\\t{}\\n\".format(\" \".join(text), yelp_ytest[i]))\n",
    "        \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(yelp_xtrain_str, vocabulary=vocabulary)\n",
    "\n",
    "# generate the one_hot representation\n",
    "yelp_xtrain = vectorizer.fit_transform(yelp_xtrain_str)\n",
    "yelp_xvalid = vectorizer.transform(yelp_xvalid_str)\n",
    "yelp_xtest = vectorizer.transform(yelp_xtest_str)\n",
    "\n",
    "# generate the BBoW representation\n",
    "yelp_xtrain_bbow = yelp_xtrain.sign()\n",
    "yelp_xvalid_bbow = yelp_xvalid.sign()\n",
    "yelp_xtest_bbow = yelp_xtest.sign()\n",
    "\n",
    "# generate the FBoW representation\n",
    "yelp_xtrain_fbow = ss.lil_matrix(yelp_xtrain.shape)\n",
    "yelp_xvalid_fbow = ss.lil_matrix(yelp_xvalid.shape)\n",
    "yelp_xtest_fbow = ss.lil_matrix(yelp_xtest.shape)\n",
    "\n",
    "for row in range(yelp_xtrain.shape[0]):\n",
    "    yelp_xtrain_fbow[row] = yelp_xtrain[row] / yelp_xtrain[row].sum()\n",
    "for row in range(yelp_xvalid.shape[0]):\n",
    "    yelp_xvalid_fbow[row] = yelp_xvalid[row] / yelp_xvalid[row].sum()\n",
    "for row in range(yelp_xtest.shape[0]):\n",
    "    yelp_xtest_fbow[row] = yelp_xtest[row] / yelp_xtest[row].sum()\n",
    "\n",
    "yelp_xtrain_fbow = yelp_xtrain_fbow.tocsr()\n",
    "yelp_xvalid_fbow = yelp_xvalid_fbow.tocsr()\n",
    "yelp_xtest_fbow = yelp_xtest_fbow.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      "[(200007, 'the', 79197), (97128, 'a', 1), (97037, 'and', 2718), (86860, 'of', 55290), (81098, 'to', 80436), (64239, 'is', 40560), (55429, 'in', 38831), (46365, 'it', 40714), (45792, 'i', 38064), (45229, 'this', 79608), (41499, 'that', 79145), (34674, 'br', 9343), (28650, 'was', 86225), (27707, 'as', 4242), (26311, 'for', 29457), (26267, 'with', 87856), (25003, 'movie', 51764), (24999, 'but', 10738), (22526, 'film', 28204), (19990, 'on', 55728), (18129, 'not', 54483), (17664, 'his', 36444), (17658, 'you', 89167), (17469, 'are', 3841), (16692, 'have', 35105), (16014, 'be', 6427), (15909, 'he', 35221), (15230, 'one', 55775), (14972, 'its', 40826), (14017, 'all', 1928), (13886, 'at', 4559), (13507, 'by', 10855), (12858, 'an', 2633), (12405, 'they', 79434), (12235, 'who', 87348), (12104, 'from', 30375), (11845, 'so', 73258), (11692, 'like', 45380), (10801, 'her', 35770), (10592, 'just', 42094), (10482, 'or', 56204), (10357, 'about', 175), (10014, 'if', 38259), (9972, 'has', 34970), (9788, 'out', 56588), (9380, 'some', 73549), (9228, 'there', 79372), (9041, 'what', 87088), (8703, 'good', 32557), (8499, 'when', 87160)]\n",
      "10000\n",
      "(15000, 10000) (10000, 10000) (25000, 10000)\n",
      "198 0.0206200666667\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 46)\t1\n",
      "  (0, 56)\t1\n",
      "  (0, 102)\t1\n",
      "  (0, 105)\t1\n",
      "  (0, 114)\t1\n",
      "  (0, 131)\t1\n",
      "  (0, 152)\t1\n",
      "  (0, 165)\t1\n",
      "  (0, 169)\t1\n",
      "  (0, 205)\t1\n",
      "  (0, 241)\t1\n",
      "  (0, 533)\t1\n",
      "  (0, 829)\t1\n",
      "  (0, 881)\t1\n",
      "  (0, 885)\t1\n",
      "  :\t:\n",
      "  (14999, 334)\t1\n",
      "  (14999, 386)\t1\n",
      "  (14999, 561)\t1\n",
      "  (14999, 587)\t1\n",
      "  (14999, 606)\t1\n",
      "  (14999, 657)\t1\n",
      "  (14999, 958)\t1\n",
      "  (14999, 1048)\t1\n",
      "  (14999, 1303)\t1\n",
      "  (14999, 1479)\t1\n",
      "  (14999, 1530)\t1\n",
      "  (14999, 1625)\t1\n",
      "  (14999, 2381)\t1\n",
      "  (14999, 2625)\t1\n",
      "  (14999, 2824)\t1\n",
      "  (14999, 3011)\t1\n",
      "  (14999, 3065)\t1\n",
      "  (14999, 3561)\t1\n",
      "  (14999, 4957)\t1\n",
      "  (14999, 5515)\t1\n",
      "  (14999, 6717)\t1\n",
      "  (14999, 8429)\t1\n",
      "  (14999, 8604)\t1\n",
      "  (14999, 9034)\t1\n",
      "  (14999, 9219)\t1\n",
      "1 0.0123665\n",
      "  (0, 0)\t0.047619047619\n",
      "  (0, 3)\t0.0238095238095\n",
      "  (0, 5)\t0.0714285714286\n",
      "  (0, 9)\t0.0238095238095\n",
      "  (0, 10)\t0.0238095238095\n",
      "  (0, 13)\t0.0238095238095\n",
      "  (0, 14)\t0.0714285714286\n",
      "  (0, 16)\t0.047619047619\n",
      "  (0, 23)\t0.0238095238095\n",
      "  (0, 32)\t0.0238095238095\n",
      "  (0, 46)\t0.0238095238095\n",
      "  (0, 56)\t0.0238095238095\n",
      "  (0, 102)\t0.0238095238095\n",
      "  (0, 105)\t0.0238095238095\n",
      "  (0, 114)\t0.0238095238095\n",
      "  (0, 131)\t0.0238095238095\n",
      "  (0, 152)\t0.0238095238095\n",
      "  (0, 165)\t0.0238095238095\n",
      "  (0, 169)\t0.0238095238095\n",
      "  (0, 205)\t0.0238095238095\n",
      "  (0, 241)\t0.0238095238095\n",
      "  (0, 533)\t0.0238095238095\n",
      "  (0, 829)\t0.0238095238095\n",
      "  (0, 881)\t0.0238095238095\n",
      "  (0, 885)\t0.0238095238095\n",
      "  :\t:\n",
      "  (14999, 334)\t0.015625\n",
      "  (14999, 386)\t0.015625\n",
      "  (14999, 561)\t0.015625\n",
      "  (14999, 587)\t0.015625\n",
      "  (14999, 606)\t0.015625\n",
      "  (14999, 657)\t0.015625\n",
      "  (14999, 958)\t0.015625\n",
      "  (14999, 1048)\t0.015625\n",
      "  (14999, 1303)\t0.015625\n",
      "  (14999, 1479)\t0.015625\n",
      "  (14999, 1530)\t0.015625\n",
      "  (14999, 1625)\t0.015625\n",
      "  (14999, 2381)\t0.015625\n",
      "  (14999, 2625)\t0.015625\n",
      "  (14999, 2824)\t0.015625\n",
      "  (14999, 3011)\t0.015625\n",
      "  (14999, 3065)\t0.015625\n",
      "  (14999, 3561)\t0.015625\n",
      "  (14999, 4957)\t0.015625\n",
      "  (14999, 5515)\t0.015625\n",
      "  (14999, 6717)\t0.015625\n",
      "  (14999, 8429)\t0.015625\n",
      "  (14999, 8604)\t0.015625\n",
      "  (14999, 9034)\t0.015625\n",
      "  (14999, 9219)\t0.015625\n",
      "0.393939393939 0.0001\n"
     ]
    }
   ],
   "source": [
    "#Preprocess and convert the IMDB dataset\n",
    "\n",
    "# train set\n",
    "with open(\"hwk3_datasets/IMDB-train.txt\", \"r\") as myfile:\n",
    "    imdb_train = myfile.readlines()\n",
    "    \n",
    "# validation set    \n",
    "with open(\"hwk3_datasets/IMDB-valid.txt\", \"r\") as myfile:\n",
    "    imdb_valid = myfile.readlines()\n",
    "    \n",
    "# test set\n",
    "with open(\"hwk3_datasets/IMDB-test.txt\", \"r\") as myfile:\n",
    "    imdb_test = myfile.readlines()\n",
    "    \n",
    "imdb_ytrain = [line.split(\"\\t\")[-1][0] for line in imdb_train]\n",
    "imdb_yvalid = [line.split(\"\\t\")[-1][0] for line in imdb_valid]\n",
    "imdb_ytest = [line.split(\"\\t\")[-1][0] for line in imdb_test]\n",
    "\n",
    "# preprocess the data\n",
    "imdb_xtrain_str = [re.sub(r'[^a-zA-Z ]', \"\", line).lower() for line in imdb_train]\n",
    "imdb_xvalid_str = [re.sub(r'[^a-zA-Z ]', \"\", line).lower() for line in imdb_valid]\n",
    "imdb_xtest_str = [re.sub(r'[^a-zA-Z ]', \"\", line).lower() for line in imdb_test]\n",
    "\n",
    "# get unique words\n",
    "words = [text.split(\" \") for text in imdb_xtrain_str]\n",
    "unique_words = set([word for text in words for word in text])\n",
    "vocabulary = dict([(word, i) for i, word in enumerate(sorted(unique_words))])\n",
    "\n",
    "#count word occurrences\n",
    "word_counts = np.zeros(len(unique_words), dtype=np.int32)\n",
    "for text in words:     \n",
    "    # vocabulary[0] = '' (blank character) so we exclude it\n",
    "    index_map = [vocabulary[word] for word in text if vocabulary[word]]\n",
    "    word_counts += np.bincount(np.array(index_map), minlength=len(unique_words))\n",
    "    \n",
    "# get 10000 most frequent words\n",
    "frequent_words = sorted(zip(word_counts, sorted(unique_words), range(len(unique_words))))\n",
    "frequent_words.reverse()\n",
    "frequent_words = frequent_words[:10000]\n",
    "vocabulary = dict([(word[1], i) for i, word in enumerate(frequent_words)])\n",
    "\n",
    "#save the vocabulary\n",
    "with open(\"my_datasets/IMDB-vocab.txt\", \"w\") as myfile:\n",
    "    for word in frequent_words:\n",
    "        myfile.write(\"{} {} {}\\n\".format(word[1], vocabulary[word[1]], word[0]))\n",
    "\n",
    "# convert input to int representation\n",
    "imdb_xtrain = [[vocabulary[word] for word in text if word in vocabulary] for text in words]\n",
    "\n",
    "valid_words = [text.split(\" \") for text in imdb_xvalid_str]\n",
    "imdb_xvalid = [[vocabulary[word] for word in text if word in vocabulary] for text in valid_words]\n",
    "\n",
    "test_words = [text.split(\" \") for text in imdb_xtest_str]\n",
    "imdb_xtest = [[vocabulary[word] for word in text if word in vocabulary] for text in test_words]\n",
    "\n",
    "# save training set\n",
    "with open(\"my_datasets/IMDB-train.txt\", \"w\") as myfile:\n",
    "    for i, text in enumerate(imdb_xtrain):\n",
    "        text = [str(i) for i in text]\n",
    "        myfile.write(\"{}\\t{}\\n\".format(\" \".join(text), imdb_ytrain[i]))\n",
    "\n",
    "# save validation set\n",
    "with open(\"my_datasets/IMDB-valid.txt\", \"w\") as myfile:\n",
    "    for i, text in enumerate(imdb_xvalid):\n",
    "        text = [str(i) for i in text]\n",
    "        myfile.write(\"{}\\t{}\\n\".format(\" \".join(text), imdb_yvalid[i]))\n",
    "\n",
    "# save test set\n",
    "with open(\"my_datasets/IMDB-test.txt\", \"w\") as myfile:\n",
    "    for i, text in enumerate(imdb_xtest):\n",
    "        text = [str(i) for i in text]\n",
    "        myfile.write(\"{}\\t{}\\n\".format(\" \".join(text), imdb_ytest[i]))\n",
    "        \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(imdb_xtrain_str, vocabulary=vocabulary)\n",
    "\n",
    "# generate the one_hot representation\n",
    "imdb_xtrain = vectorizer.fit_transform(imdb_xtrain_str)\n",
    "imdb_xvalid = vectorizer.transform(imdb_xvalid_str)\n",
    "imdb_xtest = vectorizer.transform(imdb_xtest_str)\n",
    "\n",
    "# generate the BBoW representation\n",
    "imdb_xtrain_bbow = imdb_xtrain.sign()\n",
    "imdb_xvalid_bbow = imdb_xvalid.sign()\n",
    "imdb_xtest_bbow = imdb_xtest.sign()\n",
    "print(imdb_xtrain_bbow)\n",
    "print(imdb_xtrain_bbow.max(), imdb_xtrain_bbow.mean())\n",
    "\n",
    "# generate the FBoW representation\n",
    "imdb_xtrain_fbow = ss.lil_matrix(imdb_xtrain.shape)\n",
    "imdb_xvalid_fbow = ss.lil_matrix(imdb_xvalid.shape)\n",
    "imdb_xtest_fbow = ss.lil_matrix(imdb_xtest.shape)\n",
    "\n",
    "for row in range(imdb_xtrain.shape[0]):\n",
    "    imdb_xtrain_fbow[row] = imdb_xtrain[row] / imdb_xtrain[row].sum()\n",
    "for row in range(imdb_xvalid.shape[0]):\n",
    "    imdb_xvalid_fbow[row] = imdb_xvalid[row] / imdb_xvalid[row].sum()\n",
    "for row in range(imdb_xtest.shape[0]):\n",
    "    imdb_xtest_fbow[row] = imdb_xtest[row] / imdb_xtest[row].sum()\n",
    "\n",
    "imdb_xtrain_fbow = imdb_xtrain_fbow.tocsr()\n",
    "imdb_xvalid_fbow = imdb_xvalid_fbow.tocsr()\n",
    "imdb_xtest_fbow = imdb_xtest_fbow.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of uniform classifier: 0.1945\n",
      "F1-score of majority-class classifier: 0.351\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Yelp dataset, binary bag-of-words\n",
    "# a) dummy classifiers\n",
    "\n",
    "# train uniform classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "uniform_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "uniform_classifier.fit(yelp_xtrain_bbow, yelp_ytrain)\n",
    "y_pred = uniform_classifier.predict(yelp_xtest_bbow)\n",
    "\n",
    "from sklearn import metrics\n",
    "uniform_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "# train majority-class classifier\n",
    "majority_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "majority_classifier.fit(yelp_xtrain_bbow, yelp_ytrain)\n",
    "y_pred = majority_classifier.predict(yelp_xtest_bbow)\n",
    "\n",
    "majority_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"F1-score of uniform classifier: {}\".format(uniform_f1))\n",
    "print(\"F1-score of majority-class classifier: {}\".format(majority_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.7481534   0.74507653  0.73864067  0.73223012  0.72402541  0.70910221\n",
      "  0.69192267  0.66987177  0.62856417  0.59115338]\n",
      "Train scores std: [ 0.00140592  0.00174038  0.0014971   0.00154089  0.00140623  0.00214883\n",
      "  0.00171123  0.00172716  0.00221024  0.00113853]\n",
      "Test scores: [ 0.41   0.419  0.419  0.417  0.42   0.415  0.403  0.406  0.398  0.389]\n",
      "Test scores std: [ 0.02134289  0.02111393  0.01882846  0.01063698  0.01744049  0.02133364\n",
      "  0.01624278  0.01788632  0.02449725  0.02907265]\n",
      "The best hyperparameters are: {'alpha': 0.02}\n",
      "The best fit F1-score on the test set is: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Yelp dataset, binary bag-of-words\n",
    "# Train Naive Bayes\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "parameters = [{'alpha': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]}]\n",
    "\n",
    "# do a predefined train / test split\n",
    "test_fold = []\n",
    "for i in range(yelp_xtrain_bbow.shape[0]):\n",
    "    test_fold.append(-1)\n",
    "for i in range(yelp_xvalid_bbow.shape[0]):\n",
    "    test_fold.append(random.randint(0, 4))\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(BernoulliNB(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "y_combined = np.concatenate((yelp_ytrain, yelp_yvalid))\n",
    "x_combined = ss.vstack([yelp_xtrain_bbow, yelp_xvalid_bbow])\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(yelp_xtest_bbow)\n",
    "bayes_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(bayes_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.42620775  0.395152    0.39512633  0.36142068  0.35292311  0.35292311\n",
      "  0.35292311  0.62874282  0.44909434  0.40789675  0.39050827  0.36902495\n",
      "  0.35292311  0.35292311]\n",
      "Train scores std: [ 0.00308289  0.00083546  0.00086424  0.01728205  0.00075626  0.00075626\n",
      "  0.00075626  0.00352712  0.00534925  0.00249553  0.00519677  0.00066196\n",
      "  0.00075626  0.00075626]\n",
      "Test scores: [ 0.409  0.383  0.385  0.359  0.356  0.356  0.356  0.391  0.411  0.394\n",
      "  0.379  0.363  0.356  0.356]\n",
      "Test scores std: [ 0.04100082  0.03365397  0.03563238  0.02740243  0.02911196  0.02911196\n",
      "  0.02911196  0.02375802  0.01382766  0.01905018  0.03704381  0.02575423\n",
      "  0.02911196  0.02911196]\n",
      "The best hyperparameters are: {'criterion': 'entropy', 'min_impurity_decrease': 0.002}\n",
      "The best fit F1-score on the test set is: 0.394\n"
     ]
    }
   ],
   "source": [
    "# Yelp dataset, binary bag-of-words\n",
    "# Train Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# min_impurity_decrease is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'criterion': ['gini', 'entropy'],\n",
    "             'min_impurity_decrease': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(yelp_xtest_bbow)\n",
    "decision_tree_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(decision_tree_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.60428346  0.64061531  0.63397593  0.70058953  0.68623068  0.77687172\n",
      "  0.73546191  0.83166658  0.78658997  0.88205034  0.85256394  0.93720476\n",
      "  0.89879479  0.96599986  0.9372307   0.98120516  0.97243544  0.9922821\n",
      "  0.98569245  0.99630765]\n",
      "Train scores std: [ 0.00206513  0.00100087  0.00262079  0.00120149  0.00179079  0.00059332\n",
      "  0.00081596  0.00125983  0.00089597  0.00164922  0.00109523  0.00066938\n",
      "  0.00094661  0.00098238  0.00121008  0.00046132  0.00094179  0.00029555\n",
      "  0.00037991  0.00020575]\n",
      "Test scores: [ 0.463  0.492  0.466  0.504  0.494  0.512  0.499  0.499  0.492  0.499\n",
      "  0.489  0.482  0.464  0.479  0.47   0.469  0.46   0.455  0.455  0.447]\n",
      "Test scores std: [ 0.02815831  0.04301725  0.03278227  0.03835453  0.04212933  0.03407927\n",
      "  0.03400716  0.03404094  0.02984264  0.03654571  0.03346512  0.03480736\n",
      "  0.03559444  0.04051644  0.03268884  0.03796158  0.04690814  0.04192693\n",
      "  0.04778922  0.05143806]\n",
      "The best hyperparameters are: {'C': 0.005, 'loss': 'squared_hinge'}\n",
      "The best fit F1-score on the test set is: 0.5215\n"
     ]
    }
   ],
   "source": [
    "# Yelp dataset, binary bag-of-words\n",
    "# Train Linear SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# C is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'loss': ['hinge', 'squared_hinge'],\n",
    "               'C': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(LinearSVC(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(yelp_xtest_bbow)\n",
    "svm_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(svm_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score on the training set is: 0.7765\n",
      "The F1-score on the test set is: 0.3005\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Yelp dataset, frequency bag-of-words\n",
    "# Train Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# do a predefined train / test split\n",
    "test_fold = []\n",
    "for i in range(yelp_xtrain_fbow.shape[0]):\n",
    "    test_fold.append(-1)\n",
    "for i in range(yelp_xvalid_fbow.shape[0]):\n",
    "    test_fold.append(random.randint(0, 4))\n",
    "\n",
    "# fit the classifier\n",
    "clf = GaussianNB()\n",
    "y_combined = np.concatenate((yelp_ytrain, yelp_yvalid))\n",
    "x_combined = ss.vstack([yelp_xtrain_fbow, yelp_xvalid_fbow])\n",
    "clf.fit(x_combined.toarray(), y_combined)\n",
    "\n",
    "# report performance on training set\n",
    "y_pred = clf.predict(x_combined.toarray())\n",
    "bayes_f1 = metrics.f1_score(y_combined, y_pred, average=\"micro\")\n",
    "print(\"The F1-score on the training set is: {}\".format(bayes_f1))\n",
    "\n",
    "# report performance on test set\n",
    "y_pred = clf.predict(yelp_xtest_fbow.toarray())\n",
    "bayes_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "print(\"The F1-score on the test set is: {}\".format(bayes_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.44795051  0.40240889  0.39489833  0.36164899  0.35292321  0.35292321\n",
      "  0.35292321  0.7312312   0.49133189  0.41169294  0.38874509  0.37443968\n",
      "  0.35292321  0.35292321]\n",
      "Train scores std: [ 0.00791185  0.00507084  0.00154818  0.01801259  0.00069439  0.00069439\n",
      "  0.00069439  0.00276578  0.00496119  0.00143198  0.00361696  0.00714941\n",
      "  0.00069439  0.00069439]\n",
      "Test scores: [ 0.387  0.366  0.372  0.352  0.356  0.356  0.356  0.362  0.403  0.393\n",
      "  0.366  0.36   0.356  0.356]\n",
      "Test scores std: [ 0.05705417  0.06199634  0.05876946  0.03344202  0.02685426  0.02685426\n",
      "  0.02685426  0.02155527  0.0552321   0.05902373  0.05228011  0.03242069\n",
      "  0.02685426  0.02685426]\n",
      "The best hyperparameters are: {'criterion': 'entropy', 'min_impurity_decrease': 0.002}\n",
      "The best fit F1-score on the test set is: 0.4095\n"
     ]
    }
   ],
   "source": [
    "# Yelp dataset, frequency bag-of-words\n",
    "# Train Decision Tree\n",
    "\n",
    "# min_impurity_decrease is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'criterion': ['gini', 'entropy'],\n",
    "             'min_impurity_decrease': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(yelp_xtest_fbow)\n",
    "decision_tree_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(decision_tree_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.5738723   0.44746185  0.57487171  0.46018046  0.57487228  0.48271878\n",
      "  0.57912811  0.51033339  0.58694862  0.54864193  0.60779461  0.61687151\n",
      "  0.63923116  0.67574368  0.67584601  0.73387138  0.7303333   0.82002633\n",
      "  0.78028438  0.88097619]\n",
      "Train scores std: [ 0.00196195  0.00065744  0.00196161  0.00142629  0.00119252  0.00090376\n",
      "  0.001428    0.00030308  0.00121358  0.00155073  0.00127823  0.00067387\n",
      "  0.00092876  0.00067246  0.00124423  0.00096137  0.00080249  0.00168954\n",
      "  0.00358855  0.00218453]\n",
      "Test scores: [ 0.45   0.41   0.449  0.418  0.453  0.435  0.453  0.455  0.463  0.475\n",
      "  0.473  0.499  0.483  0.509  0.492  0.517  0.508  0.503  0.504  0.501]\n",
      "Test scores std: [ 0.0359449   0.0196809   0.03796373  0.02124244  0.03902096  0.025079\n",
      "  0.03591722  0.0155712   0.03460027  0.03241022  0.03499769  0.03785903\n",
      "  0.03307779  0.03769556  0.03333647  0.04425225  0.02544262  0.04212892\n",
      "  0.03677481  0.03172663]\n",
      "The best hyperparameters are: {'C': 20, 'loss': 'squared_hinge'}\n",
      "The best fit F1-score on the test set is: 0.513\n"
     ]
    }
   ],
   "source": [
    "# Yelp dataset, frequency bag-of-words\n",
    "# Train Linear SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# C is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'loss': ['hinge', 'squared_hinge'],\n",
    "               'C': [0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(LinearSVC(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(yelp_xtest_fbow)\n",
    "svm_f1 = metrics.f1_score(yelp_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(svm_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of uniform classifier: 0.49708\n"
     ]
    }
   ],
   "source": [
    "# Question 4: IMDB dataset, binary bag-of-words\n",
    "# a) dummy classifiers\n",
    "\n",
    "# train uniform classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "uniform_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "uniform_classifier.fit(imdb_xtrain_bbow, imdb_ytrain)\n",
    "y_pred = uniform_classifier.predict(imdb_xtest_bbow)\n",
    "\n",
    "from sklearn import metrics\n",
    "uniform_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"F1-score of uniform classifier: {}\".format(uniform_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.86753832  0.867547    0.867547    0.86753828  0.86749476  0.86741654\n",
      "  0.8673296   0.86714715  0.86679924  0.86640811]\n",
      "Train scores std: [ 0.00082522  0.00083382  0.00083382  0.00083008  0.00083585  0.00080603\n",
      "  0.00080433  0.00082977  0.00096465  0.00082998]\n",
      "Test scores: [ 0.8474  0.8474  0.8475  0.8475  0.8476  0.8478  0.8478  0.8479  0.8479\n",
      "  0.8476]\n",
      "Test scores std: [ 0.00141028  0.00141028  0.00149705  0.00149705  0.00150337  0.00159753\n",
      "  0.00159753  0.00196671  0.00227846  0.00192217]\n",
      "The best hyperparameters are: {'alpha': 0.2}\n",
      "The best fit F1-score on the test set is: 0.83816\n"
     ]
    }
   ],
   "source": [
    "# IMDB dataset, binary bag-of-words\n",
    "# Train Naive Bayes\n",
    "\n",
    "parameters = [{'alpha': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]}]\n",
    "\n",
    "# do a predefined train / test split\n",
    "test_fold = []\n",
    "for i in range(imdb_xtrain_bbow.shape[0]):\n",
    "    test_fold.append(-1)\n",
    "for i in range(imdb_xvalid_bbow.shape[0]):\n",
    "    test_fold.append(random.randint(0, 4))\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(BernoulliNB(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "y_combined = np.concatenate((imdb_ytrain, imdb_yvalid))\n",
    "x_combined = ss.vstack([imdb_xtrain_bbow, imdb_xvalid_bbow])\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(imdb_xtest_bbow)\n",
    "bayes_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(bayes_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.9427477   0.81764488  0.7537348   0.73155813  0.70456981  0.69245192\n",
      "  0.67120855  0.99990436  0.96539377  0.77720432  0.747359    0.72037097\n",
      "  0.69546     0.68399096]\n",
      "Train scores std: [  1.25271809e-03   2.56355585e-03   4.54922039e-03   4.43828786e-03\n",
      "   3.78577808e-03   8.02113907e-04   5.00822579e-04   7.97229732e-05\n",
      "   2.32554844e-03   3.20661401e-03   2.14627583e-03   4.35681115e-03\n",
      "   1.72814004e-03   5.59964126e-04]\n",
      "Test scores: [ 0.7249  0.7372  0.7353  0.7263  0.7037  0.6933  0.6666  0.7003  0.7001\n",
      "  0.7344  0.7345  0.7156  0.6959  0.6796]\n",
      "Test scores std: [ 0.01102256  0.00970658  0.00520866  0.01060235  0.00723002  0.00915777\n",
      "  0.00571048  0.0054334   0.00195401  0.00746795  0.00434344  0.00897345\n",
      "  0.01119086  0.00640535]\n",
      "The best hyperparameters are: {'criterion': 'gini', 'min_impurity_decrease': 0.0002}\n",
      "The best fit F1-score on the test set is: 0.74436\n"
     ]
    }
   ],
   "source": [
    "# IMDB dataset, binary bag-of-words\n",
    "# Train Decision Tree\n",
    "\n",
    "# min_impurity_decrease is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'criterion': ['gini', 'entropy'],\n",
    "             'min_impurity_decrease': [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(imdb_xtest_bbow)\n",
    "decision_tree_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(decision_tree_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.87284399  0.90300027  0.8888353   0.91904461  0.90931392  0.93893942\n",
      "  0.92458293  0.95401712  0.9393558   0.96681748  0.95847832  0.98175635\n",
      "  0.96995618  0.99117422  0.98222575  0.99632208  0.99361769  0.99933926\n",
      "  0.99835676  0.9999044 ]\n",
      "Train scores std: [  8.37052957e-04   2.68752643e-04   3.18718559e-04   6.92577658e-04\n",
      "   6.38119348e-04   6.34401625e-04   4.31577880e-04   3.12777600e-04\n",
      "   5.37759467e-04   3.58404465e-04   5.90461104e-04   1.72073003e-04\n",
      "   2.74835489e-04   4.38098647e-04   3.43866716e-04   2.51245357e-04\n",
      "   2.70150515e-04   9.97193618e-05   1.78678721e-04   5.06218734e-05]\n",
      "Test scores: [ 0.8594  0.8768  0.8686  0.8802  0.8765  0.8812  0.8801  0.8809  0.8795\n",
      "  0.878   0.8739  0.8684  0.8659  0.8606  0.8584  0.8546  0.8453  0.8427\n",
      "  0.8368  0.8384]\n",
      "Test scores std: [ 0.00339663  0.00366913  0.002673    0.00503717  0.00510219  0.00542678\n",
      "  0.00464403  0.0071572   0.00674953  0.00751895  0.00655     0.0058722\n",
      "  0.00731048  0.00465675  0.00443778  0.0029483   0.00421508  0.00492635\n",
      "  0.00339136  0.00526348]\n",
      "The best hyperparameters are: {'C': 0.005, 'loss': 'squared_hinge'}\n",
      "The best fit F1-score on the test set is: 0.8808\n"
     ]
    }
   ],
   "source": [
    "# IMDB dataset, binary bag-of-words\n",
    "# Train Linear SVM\n",
    "\n",
    "# C is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'loss': ['hinge', 'squared_hinge'],\n",
    "               'C': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(LinearSVC(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(imdb_xtest_bbow)\n",
    "svm_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(svm_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score on the training set is: 0.83968\n",
      "The F1-score on the test set is: 0.70228\n"
     ]
    }
   ],
   "source": [
    "# Question 5: IMDB dataset, frequency bag-of-words\n",
    "# Train Gaussian Naive Bayes\n",
    "\n",
    "# do a predefined train / test split\n",
    "test_fold = []\n",
    "for i in range(imdb_xtrain_fbow.shape[0]):\n",
    "    test_fold.append(-1)\n",
    "for i in range(imdb_xvalid_fbow.shape[0]):\n",
    "    test_fold.append(random.randint(0, 4))\n",
    "\n",
    "# fit the classifier\n",
    "clf = GaussianNB()\n",
    "y_combined = np.concatenate((imdb_ytrain, imdb_yvalid))\n",
    "x_combined = ss.vstack([imdb_xtrain_fbow, imdb_xvalid_fbow])\n",
    "clf.fit(x_combined.toarray(), y_combined)\n",
    "\n",
    "# report performance on training set\n",
    "y_pred = clf.predict(x_combined.toarray())\n",
    "bayes_f1 = metrics.f1_score(y_combined, y_pred, average=\"micro\")\n",
    "print(\"The F1-score on the training set is: {}\".format(bayes_f1))\n",
    "\n",
    "# report performance on test set\n",
    "y_pred = clf.predict(imdb_xtest_fbow.toarray())\n",
    "bayes_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "print(\"The F1-score on the test set is: {}\".format(bayes_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 1.          0.97052976  0.73725114  0.71372319  0.6991826   0.67189519\n",
      "  0.65062576  0.50056523  0.50056523  1.          1.          0.75349368\n",
      "  0.7192095   0.70334021  0.69169802  0.67173859  0.61112986  0.50056523]\n",
      "Train scores std: [ 0.          0.00058223  0.0034856   0.00280748  0.0006958   0.00074189\n",
      "  0.00059684  0.00018284  0.00018284  0.          0.          0.00200512\n",
      "  0.00217656  0.00323749  0.00621709  0.00092861  0.00146292  0.00018284]\n",
      "Test scores: [ 0.6972  0.7007  0.7274  0.7122  0.6979  0.668   0.6469  0.4935  0.4935\n",
      "  0.6943  0.6948  0.7318  0.7154  0.7018  0.6844  0.6674  0.6097  0.4935]\n",
      "Test scores std: [ 0.00629169  0.00849532  0.00795495  0.00535621  0.00641723  0.00756066\n",
      "  0.00507871  0.00210801  0.00210801  0.00923982  0.00589442  0.00549294\n",
      "  0.00408596  0.00851077  0.01237812  0.00686857  0.00642467  0.00210801]\n",
      "The best hyperparameters are: {'criterion': 'entropy', 'min_impurity_decrease': 0.001}\n",
      "The best fit F1-score on the test set is: 0.7404\n"
     ]
    }
   ],
   "source": [
    "# IMDB dataset, frequency bag-of-words\n",
    "# Train Decision Tree\n",
    "\n",
    "# min_impurity_decrease is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'criterion': ['gini', 'entropy'],\n",
    "             'min_impurity_decrease': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(imdb_xtest_fbow)\n",
    "decision_tree_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(decision_tree_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: [ 0.57381184  0.72179063  0.6716076   0.75093857  0.7064346   0.79216547\n",
      "  0.74249546  0.82106988  0.78001789  0.84631301  0.82685282  0.87431273\n",
      "  0.85342635  0.89194703  0.8756002   0.9070261   0.89815669  0.92610425\n",
      "  0.91287793  0.94167821]\n",
      "Train scores std: [ 0.03494757  0.00094499  0.00321189  0.00053611  0.00067426  0.00045316\n",
      "  0.00062641  0.0005215   0.00073729  0.00068485  0.00064122  0.00073769\n",
      "  0.0005108   0.00085407  0.00031874  0.00099155  0.00062471  0.00079673\n",
      "  0.00065617  0.00062793]\n",
      "Test scores: [ 0.5626  0.7137  0.6691  0.7413  0.7015  0.7802  0.7331  0.8102  0.7684\n",
      "  0.8313  0.8162  0.8544  0.8385  0.8675  0.8565  0.8752  0.8718  0.8806\n",
      "  0.8784  0.8824]\n",
      "Test scores std: [ 0.0384001   0.00883982  0.01005636  0.0083421   0.00896203  0.00929538\n",
      "  0.00729715  0.00795961  0.00999425  0.00854818  0.00737194  0.00397708\n",
      "  0.00769575  0.00311109  0.00495367  0.00600125  0.00484408  0.00310185\n",
      "  0.00617804  0.00214637]\n",
      "The best hyperparameters are: {'C': 100, 'loss': 'squared_hinge'}\n",
      "The best fit F1-score on the test set is: 0.88024\n"
     ]
    }
   ],
   "source": [
    "# IMDB dataset, frequency bag-of-words\n",
    "# Train Linear SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# C is used to control high-bias vs high-variance trade-off\n",
    "parameters = [{'loss': ['hinge', 'squared_hinge'],\n",
    "               'C': [0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100]}]\n",
    "\n",
    "# fit the classifier\n",
    "clf = GridSearchCV(LinearSVC(), parameters, cv=PredefinedSplit(test_fold=test_fold),\n",
    "                  scoring='f1_micro', return_train_score=True)\n",
    "clf.fit(x_combined, y_combined)\n",
    "\n",
    "# report grid search scores\n",
    "train_scores = clf.cv_results_['mean_train_score']\n",
    "train_std = clf.cv_results_['std_train_score']\n",
    "test_scores = clf.cv_results_['mean_test_score']\n",
    "test_std = clf.cv_results_['std_test_score']\n",
    "print('Train scores:', train_scores)\n",
    "print('Train scores std:', train_std)\n",
    "print('Test scores:', test_scores)\n",
    "print('Test scores std:', test_std)\n",
    "\n",
    "# report best performance\n",
    "y_pred = clf.predict(imdb_xtest_fbow)\n",
    "svm_f1 = metrics.f1_score(imdb_ytest, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"The best hyperparameters are: {}\".format(clf.best_params_))\n",
    "print(\"The best fit F1-score on the test set is: {}\".format(svm_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
